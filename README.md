# ðŸµ Gorilla Desktop Pet

**Gorilla Desktop Pet** is a cute, interactive desktop companion built with Electron.  
It features energy tracking, feeding animations, draggable states, and popup windows like todo, note, and chat.  
It also supports **offline AI chat** via local models such as RWKV or Ollama.

![gorilla-desktop](./screenshots/adver.png)

---

## âœ¨ Features

- ðŸª« Energy system (with battery and exhausted states)
- ðŸŒ Feeding animation (banana, cola, yogurt)
- ðŸ’¬ Chat window (RWKV / Ollama support)
- ðŸ“‹ Todo list window
- ðŸ“ Note-taking window
- ðŸ§² Dragging animation (struggle)
- ðŸ’» Works fully offline
- âš™ï¸ Modular architecture, easy to expand

---

## ðŸ“¦ Download

> **Large files like `ollama.exe` and models are NOT included in this repo** due to GitHub size limits.

### ðŸ”§ You must manually place them like this:

```
src/
â”œâ”€ ollama/
â”‚   â”œâ”€ ollama.exe            # Ollama executable
â”‚   â””â”€ models/               # Your RWKV or other models
```

- ðŸ”— [Download Ollama Executable](https://ollama.com/)

> âœ… After installing Ollama, use `ollama run` to download your desired model  
> (e.g. `ollama run llama3`).  
> Then, manually locate the downloaded model folder:

```
Windows: C:\Users\<YourName>\.ollama\models
macOS/Linux: ~/.ollama/models
```

> Copy the entire model folder into:  
> `src/ollama/models/`

ðŸ“‚ ä¸­æ–‡è¯´æ˜Žï¼š

ä¸‹è½½ Ollama ä¸»ç¨‹åºåŽï¼Œè¯·ä½¿ç”¨å‘½ä»¤ `ollama run æ¨¡åž‹å`ï¼ˆå¦‚ `ollama run llama3`ï¼‰ä¸‹è½½æ¨¡åž‹ã€‚  
æ¨¡åž‹é€šå¸¸ä¿å­˜åœ¨ç”¨æˆ·ä¸»ç›®å½•çš„ `.ollama/models` ä¸­ï¼Œä¸‹è½½å®ŒæˆåŽè¯·å°†æ¨¡åž‹å¤åˆ¶åˆ°é¡¹ç›®å†…çš„ `src/ollama/models/` æ–‡ä»¶å¤¹ä¸­ã€‚

- ðŸ”— [æ¨¡åž‹å‘½ä»¤å‚è€ƒï¼šollama run llama3](https://ollama.com/library)

---

## ðŸš€ Getting Started

### 1. Install dependencies

```bash
npm install
```

### 2. Place the required executable and models

ðŸ“‚ Place your `ollama.exe` and model files under `src/ollama/`  
ðŸ“‚ å°† `ollama.exe` ä¸Žæ¨¡åž‹æ–‡ä»¶æ‰‹åŠ¨æ”¾å…¥ `src/ollama/` æ–‡ä»¶å¤¹ä¸­ã€‚

### 3. Start the app

```bash
npm start
```

> If you use local AI, make sure your local server is started first (e.g. Flask / Ollama backend).

---

## ðŸ—‚ï¸ Project Structure

```
src/
â”œâ”€ assets/           # Images / GIFs (eating, exhausted, etc.)
â”œâ”€ features/         # Chat, todo, note sub-windows
â”œâ”€ renderer/         # Main UI & pet interaction
â”œâ”€ ollama/           # Holds ollama.exe and models
â”œâ”€ preload.js        # Secure API bridge
â”œâ”€ main.js           # Electron main process
```

---

## ðŸ“· Screenshots

### ðŸ’ Gorilla on Desktop

> Here's what your desktop looks like with the pet running:

![gorilla-desktop](./screenshots/adver.png)

---

## ðŸ› ï¸ Packaging

To build the `.exe` or `.dmg` app:

```bash
npm run build
```

> Requires configuration via `electron-builder` in `package.json`

---

## ðŸ“œ License

MIT License Â© 2025 [WineGorilla](https://github.com/WineGorilla)
